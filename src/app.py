# ============================== app.py (1/2) ==============================
# ‚úÖ Tek dosya Streamlit app (B√∂l√ºm 1/2)
# ‚úÖ Heuristic heatmap default ON
# ‚úÖ MediaPipe landmark (opsiyonel)
# ‚úÖ Real Grad-CAM (model+torch varsa) toggle
# ‚úÖ Hi√ßbiri kurulu olmasa bile app √ßalƒ±≈üƒ±r
# ==========================================================================

from __future__ import annotations

import os
import sys
import io
import re
import shutil
import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from src.llm_client import send_to_llm
import numpy as np
import streamlit as st
import plotly.graph_objects as go
import cv2

# Explainability default
top_frames = []        # [(img_path, score, time_sec), ...]
pdf_frames = []        # PDF i√ßin g√ºvenli varsayƒ±lan

# =========================================================
# üîß ZORUNLU PATCH ‚Äì Streamlit crash fix
# =========================================================
from typing import Dict, List, Tuple

def _get_status_placeholder():
    if "status" not in st.session_state:
        st.session_state.status = st.empty()
    return st.session_state.status

def _get_progress_bar():
    if "progress" not in st.session_state:
        st.session_state.progress = st.progress(0)
    return st.session_state.progress

# combine_cam_and_landmarks ƒ∞MZA D√úZELTME
def combine_cam_and_landmarks(
    img_rgb: np.ndarray,
    prefer_real_cam: bool,
    alpha_cam: float,
    show_landmarks: bool = True,
):
    cam_kind = "Heuristic"
    cam_img = None

    if prefer_real_cam:
        cam_img = real_gradcam_overlay(img_rgb, alpha=alpha_cam)
        if cam_img is not None:
            cam_kind = "Real Grad-CAM"

    if cam_img is None:
        cam_img = heuristic_heatmap_overlay(img_rgb, alpha=alpha_cam)
        cam_kind = "Heuristic"

    if show_landmarks:
        cam_img = draw_face_landmarks(cam_img)

    return cam_img, cam_kind


# =========================================================
# (OPSƒ∞YONEL) PDF
# =========================================================
HAS_REPORTLAB = True
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.pdfgen import canvas as rl_canvas
    from reportlab.lib.utils import ImageReader
except Exception:
    HAS_REPORTLAB = False
    A4 = None
    rl_canvas = None
    ImageReader = None

# =========================================================
# (OPSƒ∞YONEL) MediaPipe FaceMesh
# =========================================================
HAS_MP = False
mp = None
try:
    import mediapipe as mp  # type: ignore
    HAS_MP = True
except Exception:
    HAS_MP = False
    mp = None

# =========================================================
# (OPSƒ∞YONEL) Grad-CAM (pytorch-grad-cam)
# =========================================================
HAS_TORCH_CAM = False
torch = None
GradCAM = None
show_cam_on_image = None
try:
    import torch  # type: ignore
    from pytorch_grad_cam import GradCAM  # type: ignore
    from pytorch_grad_cam.utils.image import show_cam_on_image  # type: ignore
    HAS_TORCH_CAM = True
except Exception:
    HAS_TORCH_CAM = False
    torch = None
    GradCAM = None
    show_cam_on_image = None

# =========================================================
# PATH / LOG
# =========================================================
THIS_DIR = Path(__file__).resolve().parent
sys.path.append(str(THIS_DIR))
sys.path.append(str(THIS_DIR.parent))

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
try:
    import absl.logging  # type: ignore
    absl.logging.set_verbosity(absl.logging.ERROR)
except Exception:
    pass

# FFmpeg (Windows) ‚Äî senin path‚Äôin
os.environ["PATH"] = r"C:\ffmpeg\bin;" + os.environ.get("PATH", "")

# =========================================================
# BACKEND IMPORTLAR (zorunlu)
# =========================================================
# Not: Bunlar projende yoksa zaten app mantƒ±ken √ßalƒ±≈üamaz.
from src.media_io import extract_audio, extract_frames
from src.asr_text import transcribe
from src.lip_sync import lip_mismatch_score
from src.visual_score import visual_score
from src.fusion import interpret_score
from src.biomech import blink_score, headpose_score
from src.audio_artefact import audio_gan_score

# =========================================================
# (OPSƒ∞YONEL) Model eri≈üimi (Real Grad-CAM i√ßin)
# - src/visual_model.py i√ßinde `model` ve `target_layer` export edersen √ßalƒ±≈üƒ±r.
# =========================================================
visual_model = None
visual_target_layer = None
try:
    from src.visual_model import model as visual_model  # type: ignore
    from src.visual_model import target_layer as visual_target_layer  # type: ignore
except Exception:
    visual_model = None
    visual_target_layer = None

# =========================================================
# SABƒ∞TLER
# =========================================================
VIDEO_TMP = "data/tmp_upload.mp4"
AUDIO_PATH = "data/audio/gui.wav"
FRAMES_DIR = "data/frames/gui_mouth"

MAX_VIDEO_WIDTH = 720
TEXT_MIN_CHARS_FOR_LIPSYNC = 12

# =========================================================
# UI STATE (Streamlit rerun-safe)
# =========================================================
if "status_placeholder" not in st.session_state:
    st.session_state.status_placeholder = None
if "progress_bar" not in st.session_state:
    st.session_state.progress_bar = None


def _get_status_placeholder():
    if st.session_state.status_placeholder is None:
        st.session_state.status_placeholder = st.empty()
    return st.session_state.status_placeholder


def _get_progress_bar():
    if st.session_state.progress_bar is None:
        st.session_state.progress_bar = st.progress(0)
    return st.session_state.progress_bar


# =========================================================
# YARDIMCI
# =========================================================
def _ensure_dirs():
    os.makedirs("data", exist_ok=True)
    os.makedirs("data/audio", exist_ok=True)
    os.makedirs("data/frames", exist_ok=True)


def _reset_run_dirs():
    _ensure_dirs()
    if os.path.isdir(FRAMES_DIR):
        shutil.rmtree(FRAMES_DIR, ignore_errors=True)
    if os.path.isfile(AUDIO_PATH):
        try:
            os.remove(AUDIO_PATH)
        except Exception:
            pass


def _render_video(path: str):
    # Streamlit video bile≈üeni local file‚Äôƒ± direkt a√ßar ama bazen path issue √ßƒ±kar.
    # HTML video ile daha stabil.
    st.markdown(
        f"""
        <div style="max-width:{MAX_VIDEO_WIDTH}px;margin:0 auto;">
            <video controls style="width:100%;border-radius:14px;">
                <source src="{path}" type="video/mp4">
            </video>
        </div>
        """,
        unsafe_allow_html=True,
    )


def _safe(x: Any, d: float = 0.0) -> float:
    try:
        v = float(x)
        return v if np.isfinite(v) else float(d)
    except Exception:
        return float(d)


def _clip01(x: Any) -> float:
    return float(np.clip(_safe(x, 0.0), 0.0, 1.0))


def _fusion_v3(Sv: float, Sl: float, Sb: float, Sh: float, Sa: float, has_speech: bool) -> Tuple[float, Dict[str, float]]:
    # Konu≈ümalƒ± vs sessiz mod
    if has_speech:
        w = {"v": 0.45, "l": 0.20, "b": 0.10, "h": 0.10, "a": 0.15}
    else:
        w = {"v": 0.55, "l": 0.00, "b": 0.15, "h": 0.10, "a": 0.20}

    Sf = (
        w["v"] * Sv
        + w["l"] * Sl
        + w["b"] * Sb
        + w["h"] * Sh
        + w["a"] * Sa
    )
    return float(np.clip(Sf, 0.0, 1.0)), w


def _score_color(sf: float) -> str:
    return "#bb00c8" if sf < 0.35 else "#ff005d" if sf < 0.7 else "#0079d5"


def _badge(has_speech: bool) -> str:
    if has_speech:
        return "<span style='background:#123b2b;color:#b9ffdf;padding:6px 10px;border-radius:999px;font-weight:800;'>üü¢ Konu≈ümalƒ± Video</span>"
    return "<span style='background:#3b2f12;color:#ffe7b9;padding:6px 10px;border-radius:999px;font-weight:800;'>üü° Sessiz / Az Konu≈ümalƒ± Video</span>"


def _compact_bar_row(scores: Dict[str, float]):
    def one(label: str, val: float) -> str:
        pct = int(_clip01(val) * 100)
        return f"""
        <div style="flex:1;min-width:120px">
          <div style="display:flex;justify-content:space-between;gap:8px;font-size:12px;color:#ddd;margin-bottom:4px">
            <span><b>{label}</b></span><span>{val:.2f}</span>
          </div>
          <div style="background:#1e1e1e;border-radius:999px;height:8px;overflow:hidden">
            <div style="width:{pct}%;height:8px;border-radius:999px;background:linear-gradient(90deg,#00c6ff,#0072ff)"></div>
          </div>
        </div>
        """

    items = "".join([one(k, float(v)) for k, v in scores.items()])
    st.markdown(
        f"""
        <div style="display:flex;flex-wrap:wrap;gap:14px;align-items:flex-end">
          {items}
        </div>
        """,
        unsafe_allow_html=True,
    )


def _parse_frame_idx(img_path: str, fallback: int) -> int:
    name = Path(img_path).stem
    m = re.findall(r"(\d+)", name)
    if m:
        try:
            return int(m[-1])
        except Exception:
            return fallback
    return fallback


def _get_video_fps(video_path: str) -> float:
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS) if cap.isOpened() else 0.0
    cap.release()
    if fps and fps > 1e-3:
        return float(fps)
    return 25.0


def frame_to_timecode(frame_idx: int, fps: float) -> str:
    sec = frame_idx / max(fps, 1e-6)
    mm = int(sec // 60)
    ss = sec - 60 * mm
    return f"{mm:02d}:{ss:05.2f}"


# =========================================================
# Plotly Gauge
# =========================================================
def render_sf_gauge(sf: float):
    fig = go.Figure(
        go.Indicator(
            mode="gauge+number",
            value=float(sf),
            number={"font": {"size": 28}},
            title={"text": "Sf ¬∑ Nihai Risk Skoru"},
            gauge={
                "axis": {"range": [0, 1]},
                "bar": {"color": _score_color(sf)},
                "steps": [
                    {"range": [0, 0.35], "color": "#2a002f"},
                    {"range": [0.35, 0.7], "color": "#330014"},
                    {"range": [0.7, 1.0], "color": "#001c33"},
                ],
            },
        )
    )
    fig.update_layout(height=260, margin=dict(l=10, r=10, t=50, b=0))
    st.plotly_chart(fig, use_container_width=True)


def frame_explain(score: float) -> str:
    s = _clip01(score)
    if s >= 0.85:
        return "‚ö†Ô∏è Y√ºksek risk: doku/sƒ±nƒ±r artefaktƒ±, yapay keskinlik veya y√ºz √ßevresi tutarsƒ±z"
    if s >= 0.65:
        return "‚ùó Orta risk: ƒ±≈üƒ±k/g√∂lge, mimik akƒ±≈üƒ± veya detay tutarsƒ±zlƒ±ƒüƒ±"
    if s >= 0.45:
        return "‚ÑπÔ∏è D√º≈ü√ºk-orta: k√º√ß√ºk tutarsƒ±zlƒ±klar var, tek ba≈üƒ±na kanƒ±t deƒüil"
    return "‚úÖ Doƒüal: belirgin g√∂rsel tutarsƒ±zlƒ±k yok"


def render_sf_timeline(frame_scores: List[Tuple[str, float]], fps: float, title: str = "Sf (p(fake)) ¬∑ Zaman Boyunca"):
    if not frame_scores:
        return

    tmp: List[Tuple[int, float]] = []
    for j, item in enumerate(frame_scores):
        p = item[0]
        s = item[1]
        idx = _parse_frame_idx(p, j)
        tmp.append((idx, _clip01(s)))
    tmp.sort(key=lambda x: x[0])

    xs = [idx / max(fps, 1e-6) for idx, _ in tmp]
    ys = [s for _, s in tmp]

    win = 7
    ma: List[float] = []
    for i in range(len(ys)):
        a = max(0, i - win // 2)
        b = min(len(ys), i + win // 2 + 1)
        ma.append(sum(ys[a:b]) / max(1, (b - a)))

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=xs, y=ys, mode="lines", name="Sf (frame)"))
    fig.add_trace(go.Scatter(x=xs, y=ma, mode="lines", name=f"Moving Avg (win={win})"))
    fig.update_layout(
        title=title,
        height=260,
        margin=dict(l=10, r=10, t=40, b=10),
        xaxis_title="Zaman (sn)",
        yaxis_title="p(fake)",
        yaxis=dict(range=[0, 1]),
    )
    st.plotly_chart(fig, use_container_width=True)


# =========================================================
# Explainability: Heuristic Heatmap (default)
# =========================================================
def heuristic_heatmap_overlay(img_rgb: np.ndarray, alpha: float = 0.45) -> np.ndarray:
    # Laplacian magnitude heatmap
    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)
    lap = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)
    mag = np.abs(lap)
    mag = cv2.GaussianBlur(mag, (0, 0), 1.2)
    mag = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    heat_bgr = cv2.applyColorMap(mag, cv2.COLORMAP_JET)
    heat = cv2.cvtColor(heat_bgr, cv2.COLOR_BGR2RGB)
    out = cv2.addWeighted(img_rgb, 1 - float(alpha), heat, float(alpha), 0)
    return out


# =========================================================
# Explainability: Real Grad-CAM (model+torch varsa)
# =========================================================
def _torch_ready() -> bool:
    return bool(HAS_TORCH_CAM and (torch is not None) and (GradCAM is not None) and (show_cam_on_image is not None))


def real_gradcam_overlay(img_rgb: np.ndarray, alpha: float = 0.55) -> Optional[np.ndarray]:
    """
    Model/torch/cam yoksa None d√∂ner.
    Not: alpha paramƒ± burada sadece API uyumu i√ßin; show_cam_on_image zaten overlay yapƒ±yor.
    """
    if not _torch_ready():
        return None
    if visual_model is None or visual_target_layer is None:
        return None

    img_norm = img_rgb.astype(np.float32) / 255.0  # [0,1] RGB
    x = torch.tensor(img_norm).permute(2, 0, 1).unsqueeze(0)

    # g√ºvenli device
    try:
        visual_model.eval()
    except Exception:
        pass

    try:
        cam = GradCAM(model=visual_model, target_layers=[visual_target_layer])
        grayscale_cam = cam(input_tensor=x)[0]  # HxW
        cam_img = show_cam_on_image(img_norm, grayscale_cam, use_rgb=True)
        return cam_img
    except Exception:
        return None


# =========================================================
# Face landmarks (MediaPipe)
# =========================================================
_FACE_MESH = None
_MP_DRAW = None
_MP_STYLE = None

if HAS_MP and mp is not None:
    try:
        _FACE_MESH = mp.solutions.face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
        )
        _MP_DRAW = mp.solutions.drawing_utils
        _MP_STYLE = mp.solutions.drawing_styles
    except Exception:
        _FACE_MESH = None
        _MP_DRAW = None
        _MP_STYLE = None


def draw_face_landmarks(img_rgb: np.ndarray) -> np.ndarray:
    if not (HAS_MP and _FACE_MESH is not None and _MP_DRAW is not None and _MP_STYLE is not None and mp is not None):
        return img_rgb

    res = _FACE_MESH.process(img_rgb)
    if not res.multi_face_landmarks:
        return img_rgb

    out = img_rgb.copy()
    for lm in res.multi_face_landmarks:
        _MP_DRAW.draw_landmarks(
            image=out,
            landmark_list=lm,
            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,
            landmark_drawing_spec=None,
            connection_drawing_spec=_MP_STYLE.get_default_face_mesh_contours_style(),
        )
        _MP_DRAW.draw_landmarks(
            image=out,
            landmark_list=lm,
            connections=mp.solutions.face_mesh.FACEMESH_IRISES,
            landmark_drawing_spec=None,
            connection_drawing_spec=_MP_STYLE.get_default_face_mesh_iris_connections_style(),
        )
    return out


def combine_cam_and_landmarks(
    img_rgb: np.ndarray,
    prefer_real_cam: bool,
    alpha_cam: float,
    show_landmarks: bool,
) -> Tuple[np.ndarray, str]:
    """
    1) prefer_real_cam True ve real gradcam m√ºmk√ºnse -> Real Grad-CAM
    2) deƒüilse -> Heuristic
    3) show_landmarks True ise √ºst√ºne landmark bas
    """
    cam_kind = "Heuristic"
    cam_img: Optional[np.ndarray] = None

    if prefer_real_cam:
        cam_img = real_gradcam_overlay(img_rgb, alpha=float(alpha_cam))
        if cam_img is not None:
            cam_kind = "Real Grad-CAM"

    if cam_img is None:
        cam_img = heuristic_heatmap_overlay(img_rgb, alpha=float(alpha_cam))
        cam_kind = "Heuristic"

    if show_landmarks:
        cam_img = draw_face_landmarks(cam_img)

    return cam_img, cam_kind


# =========================================================
# UI: Method schema
# =========================================================
def render_method_schema():
    st.markdown(
        """
        <div style="border:1px solid rgba(255,255,255,0.15);border-radius:14px;padding:14px">
          <div style="font-weight:900;margin-bottom:8px">üß© Metod ≈ûemasƒ± (1 sayfa)</div>
          <div style="display:flex;flex-wrap:wrap;gap:10px;align-items:center;justify-content:center">
            <div style="padding:10px 14px;border-radius:12px;background:#0a1b2a;border:1px solid rgba(255,255,255,0.12)"><b>Video</b> ‚Üí Kare + Ses</div>
            <div style="font-size:18px">‚ûú</div>
            <div style="padding:10px 14px;border-radius:12px;background:#14122a;border:1px solid rgba(255,255,255,0.12)"><b>Sv</b> G√∂rsel</div>
            <div style="padding:10px 14px;border-radius:12px;background:#14122a;border:1px solid rgba(255,255,255,0.12)"><b>Sl</b> Lip-sync</div>
            <div style="padding:10px 14px;border-radius:12px;background:#14122a;border:1px solid rgba(255,255,255,0.12)"><b>Sb/Sh</b> Biyomek.</div>
            <div style="padding:10px 14px;border-radius:12px;background:#14122a;border:1px solid rgba(255,255,255,0.12)"><b>Sa</b> Audio</div>
            <div style="font-size:18px">‚ûú</div>
            <div style="padding:10px 14px;border-radius:12px;background:#0b2a16;border:1px solid rgba(255,255,255,0.12)"><b>Fusion</b> (moda g√∂re aƒüƒ±rlƒ±k)</div>
            <div style="font-size:18px">‚ûú</div>
            <div style="padding:10px 14px;border-radius:12px;background:#2a0b22;border:1px solid rgba(255,255,255,0.12)"><b>Sf</b> Nihai Risk</div>
            <div style="font-size:18px">‚ûú</div>
            <div style="padding:10px 14px;border-radius:12px;background:#0a1b2a;border:1px solid rgba(255,255,255,0.12)"><b>Explain</b>: Timeline + CAM+Landmark + Top Frames</div>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )


# =========================================================
# PDF report
# =========================================================
def generate_pdf_report(
    video_path: str,
    has_speech: bool,
    text: str,
    scores: Dict[str, float],
    weights: Dict[str, float],
    fps: float,
    top_frames: List[Tuple[str, float, str, str, np.ndarray]],  # (img_path, score, timecode, cam_kind, cam_img_rgb)
) -> Optional[bytes]:
    if not HAS_REPORTLAB or rl_canvas is None or A4 is None or ImageReader is None:
        return None

    buf = io.BytesIO()
    c = rl_canvas.Canvas(buf, pagesize=A4)
    W, H = A4  # noqa: F841

    def draw_title(y: float) -> float:
        c.setFont("Helvetica-Bold", 16)
        c.drawString(40, y, "Multimodal Deepfake Tespit Raporu")
        c.setFont("Helvetica", 10)
        c.drawString(40, y - 16, f"Tarih: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        c.drawString(40, y - 30, f"Mod: {'Konu≈ümalƒ±' if has_speech else 'Sessiz/Az konu≈üma'}   |   FPS: {fps:.2f}")
        return y - 50

    y = H - 50
    y = draw_title(y)

    c.setFont("Helvetica-Bold", 12)
    c.drawString(40, y, "Skor √ñzeti")
    y -= 18
    c.setFont("Helvetica", 10)
    line = (
        f"Sv={scores.get('Sv',0):.3f}  Sl={scores.get('Sl',0):.3f}  "
        f"Sb={scores.get('Sb',0):.3f}  Sh={scores.get('Sh',0):.3f}  "
        f"Sa={scores.get('Sa',0):.3f}  Sf={scores.get('Sf',0):.3f}"
    )
    c.drawString(40, y, line)
    y -= 16
    wline = (
        f"Aƒüƒ±rlƒ±klar: v={weights.get('v',0):.2f}  l={weights.get('l',0):.2f}  "
        f"b={weights.get('b',0):.2f}  h={weights.get('h',0):.2f}  a={weights.get('a',0):.2f}"
    )
    c.drawString(40, y, wline)
    y -= 26

    c.setFont("Helvetica-Bold", 12)
    c.drawString(40, y, "Metod (1 sayfa √∂zet)")
    y -= 18
    c.setFont("Helvetica", 10)
    c.drawString(40, y, "Video ‚Üí Kare+Ses ‚Üí (Sv,Sl,Sb,Sh,Sa) ‚Üí Fusion ‚Üí Sf ‚Üí Explain (timeline + CAM+landmark)")
    y -= 26

    c.setFont("Helvetica-Bold", 12)
    c.drawString(40, y, "Transcript (kƒ±sa)")
    y -= 18
    c.setFont("Helvetica", 9)
    t = (text or "(yok)").strip().replace("\n", " ")
    t = t[:380] + ("..." if len(t) > 380 else "")
    c.drawString(40, y, t)
    y -= 26

    c.setFont("Helvetica-Bold", 12)
    c.drawString(40, y, "En ≈û√ºpheli Kareler (CAM + Landmark)")
    y -= 14

    img_w = 240
    img_h = 160
    x0s = [40, 310]
    row_y = y - img_h

    placed = 0
    for (img_path, sc, tc, cam_kind, cam_img_rgb) in top_frames:
        col = placed % 2
        row = placed // 2
        x = x0s[col]
        yy = row_y - row * (img_h + 70)

        if yy < 80:
            c.showPage()
            y2 = H - 50
            y2 = draw_title(y2)
            c.setFont("Helvetica-Bold", 12)
            c.drawString(40, y2, "En ≈û√ºpheli Kareler (devam)")
            row_y = y2 - 14 - img_h
            yy = row_y
            placed = 0
            col = 0
            row = 0
            x = x0s[col]

        png_buf = io.BytesIO()
        bgr = cv2.cvtColor(cam_img_rgb, cv2.COLOR_RGB2BGR)
        ok, enc = cv2.imencode(".png", bgr)
        if ok:
            png_buf.write(enc.tobytes())
            png_buf.seek(0)
            c.drawImage(ImageReader(png_buf), x, yy, width=img_w, height=img_h, preserveAspectRatio=True, anchor="c")

        c.setFont("Helvetica", 9)
        c.drawString(x, yy - 14, f"p(fake)={float(sc):.2f}   time={tc}   CAM={cam_kind}")
        c.drawString(x, yy - 28, frame_explain(float(sc)))

        placed += 1
        if placed >= 4:
            break

    c.save()
    buf.seek(0)
    return buf.read()


# ============================== app.py (2/2) ==============================
# UI + PIPELINE + EXPLAINABILITY + PDF
# ==========================================================================

# =========================================================
# SAYFA
# =========================================================
st.set_page_config(
    page_title="Multimodal Deepfake",
    layout="wide",
    page_icon="üé≠"
)

st.markdown(
    """
    <div style="padding:12px;background:#0a1b2a;border-radius:12px;margin-bottom:14px;">
      <h1 style="color:white;text-align:center;margin:0;">üé≠ Multimodal Deepfake Tespit Sistemi</h1>
      <p style="color:#cfe8ff;text-align:center;margin:6px 0 0 0;">
        G√∂rsel + Lip-Sync + Biyomekanik + Audio ‚Üí Risk Skoru + Explainability
      </p>
    </div>
    """,
    unsafe_allow_html=True,
)

render_method_schema()

st.markdown(
    """
    <div style="padding:12px;border:1px solid rgba(255,255,255,0.12);border-radius:12px;margin:12px 0;">
      <div style="font-weight:900;margin-bottom:6px;">‚ÑπÔ∏è Skor A√ßƒ±klamalarƒ±</div>
      <div style="color:#d8d8d8;line-height:1.6;">
        <b>Sv</b>: G√∂rsel tutarsƒ±zlƒ±k ¬∑
        <b>Sl</b>: Ses‚Äìdudak uyumsuzluƒüu ¬∑
        <b>Sb</b>: Blink anomali ¬∑
        <b>Sh</b>: Head-pose anomali ¬∑
        <b>Sa</b>: Audio artefact ¬∑
        <b>Sf</b>: Aƒüƒ±rlƒ±klƒ± final skor
      </div>
    </div>
    """,
    unsafe_allow_html=True,
)

# =========================================================
# UPLOAD
# =========================================================
file = st.file_uploader(
    "Bir video y√ºkleyin (MP4)",
    type=["mp4"],
    key="video_uploader_main"
)


# Global skorlar (hover paneller i√ßin)
Sv = Sl = Sb = Sh = Sa = Sf = 0.0
has_speech = False
w: Dict[str, float] = {"v": 0, "l": 0, "b": 0, "h": 0, "a": 0}
frame_scores: List[Tuple[str, float]] = []
text = ""
fps = 25.0

# =========================================================
# PIPELINE
# =========================================================
if file:
    _reset_run_dirs()

    with open(VIDEO_TMP, "wb") as f:
        f.write(file.getbuffer())

    fps = _get_video_fps(VIDEO_TMP)

    status = _get_status_placeholder()
    progress = _get_progress_bar()

    # ---------------- Sidebar controls ----------------
    st.sidebar.markdown("### üéõÔ∏è Explainability Ayarlarƒ±")
    prefer_real_cam = st.sidebar.toggle("Ger√ßek Grad-CAM (model varsa)", value=True)
    show_landmarks = st.sidebar.toggle("Y√ºz landmark overlay", value=True)
    alpha_cam = st.sidebar.slider("CAM / Heatmap yoƒüunluƒüu", 0.20, 0.75, 0.45, 0.05)
    show_timeline = st.sidebar.toggle("Sf zaman grafiƒüi", value=True)

    # ---------------- Layout ----------------
    left, right = st.columns([1.25, 1.0], gap="large")

    with left:
        st.subheader("üé¨ Video")
        _render_video(VIDEO_TMP)
        st.caption(f"FPS: {fps:.2f}")

    # ---------------- Pipeline steps ----------------
    status.write("1/7 Ses √ßƒ±karƒ±lƒ±yor")
    extract_audio(VIDEO_TMP, AUDIO_PATH)
    progress.progress(14)

    status.write("2/7 Kareler √ßƒ±karƒ±lƒ±yor")
    extract_frames(VIDEO_TMP, FRAMES_DIR)
    progress.progress(28)

    status.write("3/7 Transkript")
    try:
        text = transcribe(AUDIO_PATH, "tr").strip()
    except Exception:
        text = ""
    progress.progress(42)

    status.write("4/7 Lip-sync")
    has_speech = len(text) >= TEXT_MIN_CHARS_FOR_LIPSYNC
    Sl = lip_mismatch_score(AUDIO_PATH, FRAMES_DIR) if has_speech else 0.0
    progress.progress(56)

    status.write("5/7 G√∂rsel skor")
    Sv, frame_scores = visual_score(FRAMES_DIR, True)
    progress.progress(72)

    status.write("6/7 Biyomekanik")
    Sb = blink_score(FRAMES_DIR)
    Sh = headpose_score(FRAMES_DIR)
    progress.progress(86)

    status.write("7/7 Audio")
    Sa, _ = audio_gan_score(AUDIO_PATH, True) if os.path.exists(AUDIO_PATH) else (0.0, {})
    progress.progress(100)

    # ---------------- Fusion ----------------
    Sv = _clip01(Sv)
    Sl = _clip01(Sl)
    Sb = _clip01(Sb)
    Sh = _clip01(Sh)
    Sa = _clip01(Sa)

    Sf, w = _fusion_v3(Sv, Sl, Sb, Sh, Sa, has_speech)

# =========================================================
# UPLOAD
# =========================================================


if file:
    # üî¥ right BURADA OLU≈ûUR
    left, right = st.columns([1.25, 1.0], gap="large")

    # ================= LLM REASONING =================
    llm_out = None
    try:
        llm_out = send_to_llm(
            video_id="uploaded_video",
            features=[Sv, Sl, Sb, Sh, Sa]
        )
    except Exception:
        llm_out = {
            "confidence": Sf,
            "explanation": "LLM baƒülantƒ±sƒ± yok, lokal skor kullanƒ±ldƒ±."
        }

    # ================= LEFT PANEL =================
    with left:
        st.subheader("üé¨ Video")
        _render_video(VIDEO_TMP)

    # ================= RIGHT PANEL =================
    with right:
        st.subheader("üìå Sonu√ß")
        st.markdown(_badge(has_speech), unsafe_allow_html=True)
        render_sf_gauge(Sf)

        verdict, verdict_msg = interpret_score(Sf)
        st.success(f"Sonu√ß: **{verdict.upper()}**")
        st.caption(verdict_msg)

        # üß† LLM PANELƒ∞
        if llm_out is not None:
            st.markdown("### üß† LLM A√ßƒ±klamasƒ±")
            st.metric(
                "Deepfake Confidence (LLM)",
                f"%{int(llm_out.get('confidence', Sf) * 100)}"
            )
            st.write(llm_out.get("explanation", ""))

        with st.expander("üìÑ Transcript (Whisper)"):
            st.write(text if text else "(Transkript yok)")



    # ---------------- Skor barlarƒ± ----------------
    st.markdown("---")
    st.subheader("üìä Skorlar (Compact)")
    _compact_bar_row({"Sv": Sv, "Sl": Sl, "Sb": Sb, "Sh": Sh, "Sa": Sa, "Sf": Sf})
    st.caption(
        f"Aƒüƒ±rlƒ±klar ‚Üí Sv:{w['v']:.2f} | Sl:{w['l']:.2f} | Sb:{w['b']:.2f} | "
        f"Sh:{w['h']:.2f} | Sa:{w['a']:.2f}"
    )

    if show_timeline:
        with st.expander("üìà Sf zaman grafiƒüi", expanded=True):
            render_sf_timeline(frame_scores, fps=fps)

# =========================================================
# EN ≈û√úPHELƒ∞ KARELER (3 FAZ Bƒ∞RLƒ∞KTE)
# =========================================================
st.markdown("---")
st.subheader("üî• En ≈û√ºpheli Kareler (Explainability)")

if frame_scores:
    top = sorted(frame_scores, key=lambda x: _safe(x[1]), reverse=True)
    cols = st.columns(5, gap="small")

    pdf_frames: List[Tuple[str, float, str, str, np.ndarray]] = []

    for i, item in enumerate(top):
        img_path = item[0]
        s = item[1]
        score = _clip01(s)
        frame_idx = _parse_frame_idx(img_path, i)
        tc = frame_to_timecode(frame_idx, fps)

        img_bgr = cv2.imread(img_path)
        if img_bgr is None:
            continue
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

        cam_img, cam_kind = combine_cam_and_landmarks(
            img_rgb,
            prefer_real_cam=prefer_real_cam,
            alpha_cam=alpha_cam,
            show_landmarks=show_landmarks,
        )

        with cols[i]:
            st.image(cam_img, use_container_width=True)
            st.caption(f"p(fake)={score:.2f} ¬∑ ‚è± {tc}")
            st.caption(frame_explain(score))

            with st.expander("Detay / Neden?"):
                st.write(f"**CAM t√ºr√º**: {cam_kind}")
                st.write(f"**Mod**: {'Konu≈ümalƒ±' if has_speech else 'Sessiz'}")
                st.write(f"**Toplam Sf**: `{Sf:.3f}`")

        pdf_frames.append((img_path, score, tc, cam_kind, cam_img))

# =====================================================
# VERDICT (NIHAI KARAR MANTIGI)
# =====================================================

def compute_verdict(Sf, Sv, Sa):
    """
    Basit ama g√ºvenli karar mantƒ±ƒüƒ±
    """
    if Sf >= 0.75 and Sv >= 0.65:
        return "DEEPFAKE"
    elif Sa >= 0.60 and Sf < 0.75:
        return "AI_GENERATED / COMPRESSION"
    elif Sf < 0.40 and Sv < 0.40:
        return "REAL"
    else:
        return "UNCERTAIN"


verdict = compute_verdict(Sf, Sv, Sa)


# =====================================================
# NIHAYI KARAR (PDF'DEN √ñNCE G√ñSTERƒ∞LMELƒ∞)
# =====================================================
st.subheader("üß† Nihai Karar")

if verdict == "DEEPFAKE":
    st.error("‚ö†Ô∏è Deepfake tespit edildi")
elif verdict == "AI_GENERATED / COMPRESSION":
    st.warning("ü§ñ AI √ºretimi / sƒ±kƒ±≈ütƒ±rma artefaktƒ± (deepfake deƒüil)")
elif verdict == "REAL":
    st.success("‚úÖ Ger√ßek video")
else:
    st.info("üü° ≈û√ºpheli ‚Äì manuel inceleme √∂nerilir")

# PDF i√ßin g√ºvenli frame listesi
if "top_frames" in locals() and top_frames:
    pdf_frames = [
        (img_path, s, t, "Model highlight")
        for (img_path, s, t) in top_frames
    ]
else:
    pdf_frames = []  # <<< KRƒ∞Tƒ∞K SATIR


# =====================================================
# PDF
# =====================================================
st.markdown("---")
st.subheader("üìÑ Rapor (PDF)")

pdf_bytes = generate_pdf_report(
    VIDEO_TMP,
    has_speech,
    text,
    {
        "Sv": Sv,
        "Sl": Sl,
        "Sb": Sb,
        "Sh": Sh,
        "Sa": Sa,
        "Sf": Sf,
        "Verdict": verdict,   # üëà √ñNEMLƒ∞
    },
    w,
    fps,
    pdf_frames,
)

if pdf_bytes:
    st.download_button(
        "‚¨á PDF Raporu indir",
        data=pdf_bytes,
        file_name="deepfake_report.pdf",
        mime="application/pdf",
    )
else:
    st.info("PDF i√ßin reportlab kurulu deƒüil (opsiyonel).")


# =========================================================
# √áALI≈ûTIRMA
# =========================================================
# .\.venv\Scripts\Activate.ps1
# python -m streamlit run src/app.py
