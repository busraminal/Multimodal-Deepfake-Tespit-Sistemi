{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoGcbNsHuAVdOzT6G5DO1z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/busraminal/Multimodal-Deepfake-Tespit-Sistemi/blob/main/df_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrSE-ihY-Rhb",
        "outputId": "6575d009-2ffb-4a6f-c854-9236097b8637"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.1+cpu\n",
            "Uninstalling torch-2.9.1+cpu:\n",
            "  Successfully uninstalled torch-2.9.1+cpu\n",
            "Found existing installation: torchvision 0.24.1+cpu\n",
            "Uninstalling torchvision-0.24.1+cpu:\n",
            "  Successfully uninstalled torchvision-0.24.1+cpu\n",
            "Found existing installation: torchaudio 2.9.1+cpu\n",
            "Uninstalling torchaudio-2.9.1+cpu:\n",
            "  Successfully uninstalled torchaudio-2.9.1+cpu\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torch-2.9.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Using cached https://download.pytorch.org/whl/cpu/torch-2.9.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl (184.4 MB)\n",
            "Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl (1.9 MB)\n",
            "Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl (495 kB)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.9.1+cpu torchaudio-2.9.1+cpu torchvision-0.24.1+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pydantic sentence-transformers faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaZn0TTa--An",
        "outputId": "5c7236e7-f5b1-4415-c93e-1af8cf27fe03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.50.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.1+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.11)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBXit31x-TxG",
        "outputId": "055eaa75-c2fd-4363-d043-c91aec33815b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.9.1+cpu\n",
            "cuda: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "print(\"sentence-transformers OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFy3R0tU_nvb",
        "outputId": "1913bc85-c88b-4e02-ee5b-2f10debb9448"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence-transformers OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# basit test\n",
        "d = 5\n",
        "index = faiss.IndexFlatIP(d)\n",
        "\n",
        "x = np.random.rand(3, d).astype(\"float32\")\n",
        "faiss.normalize_L2(x)\n",
        "index.add(x)\n",
        "\n",
        "D, I = index.search(x[:1], 2)\n",
        "print(\"faiss OK\", D, I)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7mmwBiB_3Wr",
        "outputId": "3539c3df-1945-4168-e0b7-b8ed2e5c78a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faiss OK [[0.9999999 0.9402309]] [[0 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 1) RAG verisini yÃ¼kle\n",
        "with open(\"rag_knowledge.json\", encoding=\"utf-8\") as f:\n",
        "    rag_data = json.load(f)\n",
        "\n",
        "texts = [f\"[{d['category']}] {d['text']}\" for d in rag_data]\n",
        "\n",
        "print(\"RAG entries:\", len(texts))\n",
        "\n",
        "# 2) Embedding modeli\n",
        "emb_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "embs = emb_model.encode(texts, normalize_embeddings=True)\n",
        "embs = np.array(embs, dtype=\"float32\")\n",
        "\n",
        "# 3) FAISS index\n",
        "index = faiss.IndexFlatIP(embs.shape[1])\n",
        "index.add(embs)\n",
        "\n",
        "print(\"Index size:\", index.ntotal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSbkEnQcAKLt",
        "outputId": "807a4a7b-3af0-429d-c7c9-efeeb5853c29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG entries: 9\n",
            "Index size: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, k=3):\n",
        "    q = emb_model.encode([query], normalize_embeddings=True)\n",
        "    q = np.array(q, dtype=\"float32\")\n",
        "    _, I = index.search(q, k)\n",
        "    return [texts[i] for i in I[0]]\n",
        "\n",
        "# test sorgusu\n",
        "results = retrieve(\"lip sync uyumsuzlugu deepfake\", k=3)\n",
        "\n",
        "print(\"Retrieved:\")\n",
        "for r in results:\n",
        "    print(\"-\", r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot7fyMZIAR2Y",
        "outputId": "46542313-cc13-4374-a09a-16ea68e89f16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved:\n",
            "- [context] Sessiz videolarda deepfake tespiti aÄŸÄ±rlÄ±klÄ± olarak gÃ¶rsel ve biyomekanik ipuÃ§larÄ±na dayanÄ±r. Ses ve lip-sync skorlarÄ± bu senaryoda ikincil Ã¶neme sahiptir.\n",
            "- [Sl] Sessiz veya az konuÅŸmalÄ± videolarda lip-sync analizi gÃ¼venilir deÄŸildir. Bu durumda dudak-ses uyumsuzluÄŸu skorlarÄ± deÄŸerlendirme dÄ±ÅŸÄ± bÄ±rakÄ±lmalÄ±dÄ±r.\n",
            "- [Sl] Ses ve dudak hareketleri arasÄ±ndaki zamansal uyumsuzluk, deepfake videolarda sÄ±k gÃ¶rÃ¼len bir bulgudur. Ã–zellikle 60â€“100 ms Ã¼zerindeki gecikmeler, yapay konuÅŸma senkronizasyonuna iÅŸaret edebilir.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, Header, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "import threading, uvicorn\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "APP_TOKEN = \"mina-secret\"\n",
        "\n",
        "class AnalyzeReq(BaseModel):\n",
        "    video_id: str\n",
        "    scores: List[float]  # [Sv, Sl, Sb, Sh, Sa, Sf]\n",
        "\n",
        "class AnalyzeResp(BaseModel):\n",
        "    confidence: float\n",
        "    explanation: str\n",
        "\n",
        "@app.post(\"/analyze\", response_model=AnalyzeResp)\n",
        "def analyze(\n",
        "    req: AnalyzeReq,\n",
        "    x_token: Optional[str] = Header(default=None)\n",
        "):\n",
        "    if x_token != APP_TOKEN:\n",
        "        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n",
        "\n",
        "    Sv, Sl, Sb, Sh, Sa, Sf = req.scores\n",
        "\n",
        "    # ðŸ”¹ RAG query (feature-aware, basit versiyon)\n",
        "    if Sa < 0.1 and Sl < 0.1:\n",
        "        query = \"silent video deepfake detection rules\"\n",
        "    elif Sl > 0.5:\n",
        "        query = \"lip sync mismatch deepfake\"\n",
        "    else:\n",
        "        query = \"multimodal deepfake forensic explanation\"\n",
        "\n",
        "    ctx_list = retrieve(query, k=3)\n",
        "    ctx = \"\\n\".join(ctx_list)\n",
        "\n",
        "    explanation = f\"\"\"\n",
        "SYSTEM:\n",
        "You are an AI assistant explaining a multimodal deepfake analysis to a non-technical user.\n",
        "Answer the user's question clearly and concisely.\n",
        "Do NOT repeat the analysis summary verbatim.\n",
        "Use the scores only as justification.\n",
        "\n",
        "USER QUESTION:\n",
        "{question}\n",
        "\n",
        "ANALYSIS SCORES:\n",
        "Sv={Sv}, Sl={Sl}, Sb={Sb}, Sh={Sh}, Sa={Sa}, Sf={Sf}\n",
        "\n",
        "CONTEXT:\n",
        "{rag_context}\n",
        "\n",
        "\"\"\".strip()\n",
        "\n",
        "    return AnalyzeResp(confidence=Sf, explanation=explanation)\n",
        "\n",
        "# ---- RUN SERVER ----\n",
        "threading.Thread(\n",
        "    target=lambda: uvicorn.run(app, host=\"0.0.0.0\", port=8000),\n",
        "    daemon=True\n",
        ").start()\n",
        "\n",
        "print(\"FastAPI + RAG server running on port 8000\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPRwaBJlAexJ",
        "outputId": "89d03151-4f63-4a2e-ebd1-0c963570f756"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI + RAG server running on port 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n"
      ],
      "metadata": {
        "id": "pESOK4zhA-p1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ddc7e4-b45f-4bce-d678-03278a3fa53a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [4228]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cloudflared tunnel --url http://localhost:8000\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb52JL63qbL4",
        "outputId": "639c443c-f78f-4c93-d44c-629f75c933bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cloudflared: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ./cloudflared-linux-amd64 tunnel --url http://127.0.0.1:8000 --no-autoupdate > tunnel.log 2>&1 &\n"
      ],
      "metadata": {
        "id": "jm1Qa7CYqnjl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep trycloudflare tunnel.log\n"
      ],
      "metadata": {
        "id": "kf0_2BD8qqJh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f uvicorn\n",
        "!pkill -f cloudflared || true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gok86q3rgxk",
        "outputId": "51345a81-fa55-4435-cc57-f1162b8d8cf0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.py\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class AnalyzeReq(BaseModel):\n",
        "    video_id: str\n",
        "    scores: List[float]\n",
        "    question: Optional[str] = None\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"ok\": True}\n",
        "\n",
        "@app.post(\"/analyze\")\n",
        "def analyze(req: AnalyzeReq):\n",
        "    question = req.question or \"Bu video neden gerÃ§ek sayÄ±ldÄ±?\"\n",
        "\n",
        "    return {\n",
        "        \"video_id\": req.video_id,\n",
        "        \"answer\": (\n",
        "            f\"Soru: {question}\\n\"\n",
        "            f\"Skorlar: {req.scores}\\n\"\n",
        "            \"SonuÃ§: Skorlar gerÃ§ek videolarla daha uyumludur.\"\n",
        "        )\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkDxBo13tZj8",
        "outputId": "92207c28-77aa-4c81-de8e-185e1e79ca26"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIMDcLottbgS",
        "outputId": "3edf4f7e-5942-4c76-94a7-eb0838522e89"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloudflared-linux-amd64    rag_knowledge.json  server.py\n",
            "cloudflared-linux-amd64.1  sample_data\t       tunnel.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup uvicorn server:app --host 0.0.0.0 --port 8000 > server.log 2>&1 &\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "76EgRIMPtmrf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://127.0.0.1:8000/health\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amnoxl09t_gM",
        "outputId": "68ac74e0-6359-4d61-f9b7-1074111d92a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"ok\":true}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ./cloudflared-linux-amd64 tunnel \\\n",
        "  --url http://127.0.0.1:8000 \\\n",
        "  --no-autoupdate > tunnel.log 2>&1 &\n"
      ],
      "metadata": {
        "id": "TB4fleIVuMgc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep trycloudflare tunnel.log | tail -n 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiGhxim1uOxS",
        "outputId": "b26dc027-9b4c-4afc-afb3-aa37210607f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-28T20:49:10Z INF |  https://talented-federal-twenty-scsi.trycloudflare.com                                    |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://talented-federal-twenty-scsi.trycloudflare.com/analyze\"\n",
        "\n",
        "payload = {\n",
        "    \"video_id\": \"pc_test_001\",\n",
        "    \"scores\": [0.82, 0.15, 0.60, 0.55, 0.02, 0.78],\n",
        "    \"question\": \"Bu video neden gerÃ§ek sayÄ±ldÄ±?\"\n",
        "}\n",
        "\n",
        "r = requests.post(url, json=payload, timeout=15)\n",
        "print(\"STATUS:\", r.status_code)\n",
        "print(\"TEXT:\", r.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn0finVuCWpR",
        "outputId": "4e0f7b3b-dbc4-4e52-fa18-5892a1bba0e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STATUS: 200\n",
            "TEXT: {\"video_id\":\"pc_test_001\",\"answer\":\"Soru: Bu video neden gerÃ§ek sayÄ±ldÄ±?\\nSkorlar: [0.82, 0.15, 0.6, 0.55, 0.02, 0.78]\\nSonuÃ§: Skorlar gerÃ§ek videolarla daha uyumludur.\"}\n"
          ]
        }
      ]
    }
  ]
}